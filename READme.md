
# ğŸ‘¨â€ğŸ’» Moacir Fernandes

### FullStack Developer | Front-End UI/UX Specialist | AI Agent Integrator

Hello! I'm **Moacir Fernandes**, a FullStack developer who merges intuitive design with solid architecture. With strong experience in **front-end UI/UX development**, **cloud deployment**, and now **local AI agent integration**, I deliver elegant and efficient solutions that scale from concept to production.

---

## ğŸš€ Latest Feature: Local AI Agent Powered by Ollama

This portfolio now features a real-time, **local AI-powered agent** using [Ollama](https://ollama.com), an open-source LLM runtime that allows you to run large language models on your own machine without relying on cloud APIs.

### ğŸ”Œ What It Does
- ğŸŒ Runs LLMs locally (no API costs or network dependency)
- ğŸ¤– Integrates models like `gemma:2b` for natural language tasks
- ğŸ§  Enables multi-role agents: **Ideator**, **Coder**, and **Reviewer**
- ğŸ’¬ Interacts via a modal interface inside the portfolio

### ğŸ› ï¸ How It Works
- Backend (`Express.js`) runs on `http://localhost:3001`
- Routes `/api/agent` proxy user messages to Ollama (`http://localhost:11434/api/generate`)
- Model: `gemma:2b` pulled locally and served
- Front-end React component handles UX and displays responses

---

## ğŸ§  Tech Stack Overview

### ğŸ¨ Front-End (UI/UX-Focused)
- **React.js**, **Vite**, **TypeScript**
- **Styled Components**, **CSS Modules**
- **Framer Motion**, **Custom Modals**
- Responsive, animated, accessible

### âš™ï¸ Back-End & APIs
- **Node.js**, **Express**
- **Custom API Routing**
- **Ollama integration via HTTP POST**

### ğŸ¤– AI & LLM Tools
- **Ollama**: lightweight local inference runtime
- **gemma:2b** model (Google-backed LLM)
- Agent roles: **Ideator**, **Coder**, **Reviewer**
- Prompt-to-response integration without cloud billing

---

## ğŸ’» Folder Structure Highlight

```
/api
  â””â”€â”€ server.js         â† Express server w/ Ollama integration
/src/components
  â””â”€â”€ AgentModal.jsx    â† Talk to Agent UI logic
```

---

## ğŸ’¡ Real Use Case

This portfolio showcases how you can **embed autonomous agents directly into user interfaces**, making it perfect for:

- Portfolios and product showcases
- Internal dashboards
- AI assistants without API dependency

---

## ğŸ“« Let's Connect

- ğŸ“§ Email: [moacirsistemax@gmail.com](mailto:moacirsistemax@gmail.com)
- ğŸ§‘â€ğŸ’» GitHub: [@Moa-fernandes](https://github.com/Moa-fernandes)
- ğŸ’¼ LinkedIn: [Moacir Fernandes](https://www.linkedin.com/in/moacir-fernandes-ba0a97a0/)


---


# ğŸ‘¨â€ğŸ’» Moacir Fernandes

### Desenvolvedor FullStack | Especialista em UI/UX | Integrador de Agentes de IA Locais

Sou **Moacir Fernandes**, desenvolvedor fullstack com paixÃ£o por design e engenharia, agora incorporando agentes de IA locais com **Ollama** diretamente no meu portfÃ³lio â€” sem dependÃªncia de APIs externas.

---

## ğŸ¤– Recurso Mais Recente: Agente de IA Local com Ollama

Este portfÃ³lio conta agora com um **agente de IA local** que roda diretamente na sua mÃ¡quina usando [Ollama](https://ollama.com), ideal para testes rÃ¡pidos, sem limites ou custos de API.

### ğŸ”Œ O Que Faz
- Executa modelos de linguagem diretamente no seu PC
- Roda o modelo `gemma:2b` para responder interaÃ§Ãµes
- Disponibiliza agentes: **Ideator**, **Coder** e **Reviewer**
- Interface em modal para conversa em tempo real

### âš™ï¸ Como Funciona
- Backend com Express escutando em `http://localhost:3001`
- Endpoint `/api/agent` envia mensagens ao Ollama local (`localhost:11434`)
- O modelo `gemma:2b` Ã© usado para gerar respostas
- Interface React com botÃ£o e modal interativo

---

## ğŸ§  Stack TÃ©cnica

### ğŸ¨ Front-End
- **React.js**, **Vite**
- **Styled Components**, **CSS puro**
- Componentes dinÃ¢micos e responsivos

### âš™ï¸ Back-End
- **Node.js**, **Express.js**
- IntegraÃ§Ã£o direta com Ollama via API local

### ğŸ¤– Ferramentas de IA
- **Ollama** como motor de inferÃªncia local
- Modelo **gemma:2b** com foco em NLP
- Respostas baseadas em prompt sem precisar da nuvem

---

## ğŸ—‚ï¸ Estrutura do Projeto

```
/api
  â””â”€â”€ server.js         â† Servidor Express com integraÃ§Ã£o Ollama
/src/components
  â””â”€â”€ AgentModal.jsx    â† UI do modal do agente com lÃ³gica de chamada
```

---

## ğŸ’¬ Casos de Uso

- Assistente no portfÃ³lio sem custo extra
- Provas de conceito com IA local
- SoluÃ§Ãµes offline com interatividade real

---

## ğŸ“« Contato

- ğŸ“§ Email: [moacirsistemax@gmail.com](mailto:moacirsistemax@gmail.com)
- ğŸ§‘â€ğŸ’» GitHub: [@Moa-fernandes](https://github.com/Moa-fernandes)
- ğŸ’¼ LinkedIn: [Moacir Fernandes](https://www.linkedin.com/in/moacir-fernandes-ba0a97a0/)


## âš¡ Vamos Construir Algo IncrÃ­vel???

Estou sempre aberto a colaboraÃ§Ãµes interessantes â€” seja para criar interfaces impactantes, resolver desafios tÃ©cnicos no back-end, integrar ferramentas de IA ou entregar produtos completos com performance e estilo. Bora conversar? ğŸš€
